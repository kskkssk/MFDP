1.  Бизнес-анализ (Business Understanding)

Организационная структура: Заказчик  - рекрутинговое агентство, HR-агентство, заинтересованные в автоматизации оценки заработной платы по резюме. Также это можно оценивать как конечный продукт для соискателей.
Основные пользователи - HR специалисты и соискатели в сфере Data Science, которым необходимо оценить рыночную стоимость их компетенций и понять какие навыки необходимо развивать.

Бизнес-цель проекта: Автоматизировать процесс оценки резюме и определения уровня зарплаты, а также предоставить пользователям рекомендации по развитию навыков для увеличения их заработной платы.

Разработанные решения:

CheckCV — сервис оценки резюме на основе AI
Сервис автоматической проверки резюме. Для пользования имеется телеграм-бот. На данный момент разрабатывается решение, позволяющее в режиме реального времени подсказывать пользователю, как улучшить резюме. 
Текущее решение предоставляет общую оценку резюме в виде рейтинга от 0 до 10. Пользователи отзываются, что такой подход малоинформативный и бесполезный.
Monica Pdf Tools -  сервис оценки резюме на основе AI
Веб сервис. Ставит оценку резюме от 0 до 100, дает информативную обратную связь по улучшению резюме.
Текущее решение дает общую оценку резюме, не рекомендуя улучшить навыки для конкретной профессии, указанной в резюме и не предсказывает зарплату по резюме
Группы в Facebook, LinkedIn - получение оценки резюме от реальных людей
Текущее решение не обеспечивает быстрый доступ к получению информации о зарплате
HH Калькулятор в HH карьера 
Текущее решение, реализованное на платформе HeadHunter, основывается на фиксированном наборе навыков для каждой профессии. Не учитывается вклад опыта работы, локации, желаемого опыта работы в заработную плату 
 Калькулятор в HH "Сколькополучатель" 
Текущее решение не учитывает вклад навыков в заработную плату, параметров слишком мало => предсказание не достоверно
Карьерные консультанты в агентстве “Эйч”. 
В текущем решении подход к каждому пользователю индивидуален, но не автоматизирован. Некоторые пользователи жалуются на неэффективность и псевдонаучность методик консультантов. 


1.1 Текущая ситуация (Assessing current solution)
Ресурсы для проекта:
Вычислительных мощностей достаточно. 
Необходимо обеспечить доступ к большим объемам данных, необходимых для обучения модели (например, наборы данных с вакансиями и уровнями зарплат). Данные будут версионироваться на удаленном хранилище s3-minio. 
Потребуется приобретение внешних данных. 
Наличие экспертов в области HR и Data Science будет полезным для консультаций по настройке модели и определению ключевых метрик.

Риски:
Сроки: Возможные задержки в разработке и тестировании модели.
Данные: Недостаток данных, плохой EDA может привести к созданию некорректной модели.
Метрики: Результаты модели не будут удовлетворять ожиданиям
Специфика задачи: сложность из-за большого количества категориальных фичей - не получится оценить прирост таргетного значения при добавлении большого множества категориальных признаков xi
План действий по уменьшению рисков:
При недостатке данных воспользоваться готовыми датасетами прошлых лет (данные могут быть не совсем актуальными для рынка), чтобы количество объектов было от  ~5000 значений
Для начала планируется построить baseline:  не учитывая вклад каждого отдельного навыка в зарплату, не обрабатывая навыки каждой вакансии вручную, обучаем catboost и предсказываем зарплату. Таким образом уже будет решена часть задачи. Далее группируем навыки по профессиям и фильтруем их, учитываем вклад каждого в зарплату. Если этот подход покажет хорошие результаты, следующим шагом будет использование более сложных моделей: AutoML и т.д. Вклад каждого признака в предсказание будет визуализирован и объяснен с помощью SHAP values, что позволит более детально понять, как ключевые факторы влияют на уровень зарплаты.
При неудовлетворительных метриках проконсультироваться по поводу разведочного анализа данных и датасета

1.2 Решаемые задачи с точки зрения аналитики (Data Mining goals)
Выбраны метрики:
Рассматривались MAE, MSE, RMSE. В итоге выбрана RMSE
MAE и MSE одинаково штрафуют за недо предсказания и пере предсказания. MAE менее чувствительна к выбросам, чем среднеквадратичная ошибка. Однако при предварительном разведочном анализе данных не выявлено большого количества выбросов, следовательно предпочтение отдается MSE. 
Среднеквадратичная ошибка сильнее штрафует за ошибки,  чем MAE. 
RMSE позволяет интерпретировать среднеквадратичную ошибку
Итог: 
Для оценки качества модели будет использоваться интерпретируемая метрика RMSE. Модель будет обучаться на данных, выраженных в рублях. Критерием успешности модели мы предварительно определяем значение RMSE в диапазоне от 15,500 до 23,500, что составляет от 10% до 15% от среднего арифметического значения зарплат.

1.3 План проекта (Project Plan)

Бизнес-анализ (Business Understanding) (20.08 - 10.09)
Обозначенные потребности, такие как оценка заработной платы и понимание необходимых навыков для развития, являются актуальными. Существующие решения не способны выполнять оценку заработной платы и навыков в резюме вместе, не существует решения для конкретной сферы - Data Science. Необходимо корректировать заявленные критерии успешности модели по мере подготовки датасета, на данный момент учтена слишком маленькая выборка значений. 

Анализ данных (Data Understanding) (26.08 - 25.09)

2.1 Сбор данных (Data collection) и версионирование DVC (26.08 - 25.09)
Слабые стороны парсинга с hh.ru - много пропусков в таргетном столбце ‘salary’. В общем доступе мало данных с заработной платой, включающих не только зарплаты, но и навыки вакансий. Необходимо ежедневно парсить данные и расширить датасет данными с сайта kaggle. 

2.2 Исследование данных (Data exploration) (11.09 - 25.09)
Загрузить репрезентативную выборку из набора данных
Провести предварительный анализ всей выборки.

Определить тип данных в каждом столбце
При необходимости преобразовать данные к нужным типам
Проверить на выбросы, отсутствующие значения, невалидные значения.

(по результатам предварительного анализа сделать визуализацию, обычно это табличка с характеристиками или какой то из
профайлеров) (ProfileReport library)
На основе предыдущего анализа выполнить очистку данных (обработать выбросы, отсутствующие значения, удалить невалидные значения)
Удалить из рассмотрения неинформативные данные. (лишние идентификаторы, служебные поля, поля с очень малым количеством значений)
Провести статистический анализ оставшихся данных
рассчитать ключевые статистики для каждого типа данных
построить распределения (тип графика выбрать в зависимости от данных, часто полезно построить гистограмму, но иногда лучше воспользоваться линейным графиком или посмотреть распределение во времени с помощью scatterplot)
     6. Провести корреляционный анализ
Для количественных данных нормализовать данные и построить матрицу корреляции Пирсона
сделать выводы на основе матрицы (найти утечки данных, найти важные признаки линейно влияющие на целевой показатель, определить гипотезы по конструированию признаков)
Для количественных и порядковых данных - построить матрицу корреляции Спирмена  сделать выводы аналогично предыдущему анализу, только учесть тип данных
Для всех данных построить матрицу корреляции Пфика
Сделать выводы на основе анализа, сделать оценку между всеми типами корреляции(на пересекающихся данных),
попытаться найти объяснения различиям.
Сделать выводы о наличии или отсутствии нелинейных связей.

7.  Провести обработку данных, на основе выводов полученных в прошлых шагах.
провести дополнительную очистку
выполнить нужный тип энкодинга (если уникальных значений < 5, то OneHot, в другом случае MeanTarget)
Сконструировать новые признаки.

8. Построить графики взаимодействия полученных данных с целевым показателем
Для количественных данных линейные графики на нормализованных данных
для категориальных данных с малым количеством категорий построить ScatterPlot во времени
для категориальных данных с большим количеством показателей построить heatmap во времени(обычно строят, только для признаков которые показывают высокие коэффициенты корреляции и потенциально интересны, пример такого графика спектрограмма в анализе звука)
9. Сделать выводы на основе проведенного анализа и учитывая особенности планируемой архитектуры модели.
Какие данные и почему нельзя использовать в модели
какие данные можно использовать без преобразования
какие данные можно использовать выполнив преобразование
какие новые признаки нужно использовать и почему
есть ли смысл использовать один набор признаков или построить разные модели на подмножестве признаков и почему.
Выделить итоговый список необходимых данных
10. Описать ожидания от модели на проанализированных данных


Подготовка данных (Data Preparation) (12.09-20.09)
Очистка данных от пропусков и выбросов. Закодировать категориальные фичи: профессия, регион. При использовании CatBoost не обрабатывать категориальные фичи. Представить опыт работы и диапазон зарплат как среднее. Далее группировка навыков и создание отдельного датасета для навыков, сгруппированным по профессиям Data science

3.1 Отбор данных (Data Selection) (11.09)
	
Определение релевантности признаков для задачи.
Исключение неполных или некачественных данных.
Проверка на коррелирующие признаки.
Определить важность описания вакансии.
Удалить признаки, где большая часть значений - пропуски.

3.2 Очистка данных (Data Cleaning) (11.09)

Пропущенные значения => нужно либо их заполнить, либо удалить из рассмотрения
Ошибки в данных => попробовать исправить вручную либо удалить из рассмотрения
Несоответствующая кодировка => привести к единой кодировке

3.3 Генерация данных (Constructing new data) (12.09)

агрегация атрибутов (расчет sum, avg, min, max, var и т.д.)
генерация кейсов (SMOGN при несбалансированном распределении для задачи регрессии)
конвертация типов данных для использования в разных моделях (например CHAID работает с номинальными данными)
нормализация атрибутов (feature scaling)
заполнение пропущенных данных (missing data imputation).

3.4 Версионирование данных (Data versioning) (12.09 - 20.09)

разбиваем данные на train, test, val
загружаем данные в хранилище используя пайплайн DVC

Моделирование (Modeling) (15.09-25.09)
Предполагается использовать алгоритм регрессии для предсказания зарплаты. Основной метрикой для оценки качества моделей будет RMSE, так как она лучше интерпретирует среднюю ошибку в предсказании заработной платы. Важно будет провести кросс-валидацию и оптимизацию гиперпараметров для повышения точности предсказаний. Предполагается использование изначально бустингов, затем усложненных (AutoML) на табличных данных. 

Выбор алгоритмов (Selecting the modeling technique)
	Baseline -> CatBoost на первоначальных данных без кодировки категориальных фичей для прогноза зарплаты. При условии, что все хорошо ->  сделать новый датасет с сгруппированными навыками по профессиям. Обучить его на CatBoostRegressor. Далее пробовать AutoML.
Планирование тестирования (Generating a test design)
Обучение моделей (Building the models)
Оценка результатов (Assessing the model)
Оценка метрики RMSE -> корректировка оптимальных значений.
оценить, готова ли модель к внедрению в хранилище,
достигаются ли заданные критерии качества,
оценить результаты с точки зрения достижения бизнес-целей. 

Прежде чем переходить к внедрению нужно попробовать все модели, проверить модель еще раз, если результат слишком хороший.

Оценка результата (Evaluation) (15.09 - 25.09)
Оценка эффективности модели на тестовых данных. Предварительно оценка успешности модели RMSE в диапазоне от 15,500 до 23,500.
SHAP values помогут объяснить результаты модели, интерпретировать их, выявить проблемы сдвига и утечки данных 
	Результатом предыдущего шага является построенная математическая модель (model), а также найденные закономерности (findings). На пятом шаге мы оцениваем результаты проекта.

5.1 Оценка результатов моделирования (Evaluating the results) (20.09-25.09)
Предварительно если модель предсказывает зарплату с RMSE в пределах от 15,500 до 23,500, это указывает на приемлемую точность предсказаний в зависимости от средней зарплаты. Проверка работы SHAP values. 
Точные результаты помогут HR-специалистам и соискателям в оценке рыночной стоимости компетенций.  Оценка вклада каждого навыка в зарплату поможет соискателям в развитии себя в сфере работы с данными
Необходимо проверить, найдена ли какая-то новая ценная информация, которую стоит выделить отдельно

5.2 Разбор полетов (Review the process) (20.09-25.09)
Необходимо проанализировать ход проекта и сформулировать его сильные и слабые стороны. Для этого нужно пройтись по всем
шагам:
Можно ли было какие-то шаги сделать более эффективными?
Какие были допущены ошибки и как их избежать в будущем?
Были ли не сработавшие гипотезы? Если да, стоит ли их повторять?
Были ли неожиданности при реализации шагов? Как их предусмотреть в будущем?

5.3 Принятие решения (Determining the next steps)
Далее нужно либо внедрять модель, если она устраивает заказчика, либо, если виден потенциал для улучшения, попытаться еще ее улучшить.


Внедрение (Deployment) (15.09 - 13.10)
Создание веб-сервиса и телеграм-бота, который будет доступен пользователям для оценки резюме и предсказания заработной платы.
При внедрении модели в продакшн SHAP values можно использовать для предоставления пользователям дополнительной информации о том, почему модель сделала то или иное предсказание. В интерфейсе веб-сервиса или телеграм-бота можно показать пользователю, какой опыт или навыки наиболее сильно повлияли на предсказанную зарплату. 
Обеспечение стабильной работы модели, её интеграции с другими системами, а также возможность обновления данных и модели по мере появления новых данных. Также потребуется разработать документацию и обучить конечных пользователей, чтобы они могли эффективно использовать созданное решение.
В случае успешного завершения проекта, результатом будет сервис, который сможет автоматически оценивать резюме и предсказывать уровень заработной платы, а также предлагать рекомендации по развитию навыков. Это позволит повысить эффективность работы HR специалистов и помочь соискателям в улучшении своих карьерных перспектив.
На данном шаге осуществляется внедрение модели (если проект предполагает этап внедрения). Причем под внедрением может
пониматься как физическое добавление функционала, так и инициирование изменений в бизнес-процессах компании.

6.1 Планирование развертывания (Planning Deployment)
Внедрение модели в работу телеграм-бота и сервиса. Внедрение интерпретации результатов модели (SHAP values). При прогнозе зарплаты дополнительно выводится информация, интерпретирующая результат.
 Если какой то навык положительно влияет на рост зарплаты, пользователю будет уведомлен о том , что данный навык надо развивать / опыт работы  увеличить / релоцироваться
Мониторинг модели будет проводиться в ClearML

6.2 Настройка мониторинга модели (Planning Monitoring)

Основные вопросы мониторинга:
Отслеживание у модели метрики RMSE

Модель устареет при изменении рынка труда, снижении точности предсказаний и будет требовать обновления

A/B тесты: определиться с параметрами. Предварительно:

Основная цель: Оценить, какая формулировка призыва к действию (CTA) приводит к большему количеству кликов на кнопку.

Вариант A: "Хотите улучшить свою зарплату? Нажмите здесь для подробностей".

Вариант B: "Узнайте, как поднять свою зарплату!".

Гипотезы: Вариант А содержит прямой призыв к действию, вариант B взывает к интересу и эмоциональному аспекту.

	Основные метрики: выручка на пользователя, конверсия из открытия бота (сервиса) в загрузку резюме
	Вспомогательные метрики: конверсия по совершению целевого действия

	Формирование групп (разбиение): Случайное распределение. Пока исходная выборка не очень большая, настолько большие группы, насколько возможно. Пользователи независимы.
	
	Сбор метрик (продолжительность): 1- 2 недели (необходима оценка рабочих дней и выходных)
 
Размер групп и длительность необходимо увеличивать для достижения статистически значимых результатов

6.3 Документация (documentation)
Подготовка технической документации, руководства для пользователей.

